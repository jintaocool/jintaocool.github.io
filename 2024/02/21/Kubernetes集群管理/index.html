<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
       
      <meta name="keywords" content="博客" />
       
      <meta name="description" content="日常随笔" />
      
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>Kubernetes集群管理 |  Lijintao&#39;s Blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <link rel="alternate" href="/atom.xml" title="Lijintao's Blog" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      <section class="outer">
  <article
  id="Kubernetes-Kubernetes集群管理"
  class="article article-type-Kubernetes"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Kubernetes集群管理
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2024/02/21/Kubernetes%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/" class="article-date">
  <time datetime="2024-02-21T09:31:04.000Z" itemprop="datePublished">2024-02-21</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Kubernetes/">Kubernetes</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">7.4k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">36 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p>Kubernetes作为容器的编排平台，它是以集群的形式为业务提供服务。所以在日常的工作中，作为Kubernetes平台的维护者，会经常对集群进行管理。</p>
<p>这里，我将集群管理分为以下几种：<img src="/images/1708507702-fd337dd8e46e37add85962854282d406.png" alt="图片"></p>
<h1 id="安装集群"><a href="#安装集群" class="headerlink" title="安装集群"></a>安装集群</h1><h2 id="前置说明"><a href="#前置说明" class="headerlink" title="前置说明"></a>前置说明</h2><p>Kubernetes的集群安装分为：kubeadm安装和二进制安装。在这里，只会介绍kubeadm的安装。</p>
<p>安装说明：</p>
<blockquote>
<p>集群节点：2个<br>IP信息：<br>master：192.168.205.128<br>node：192.168.205.128<br>Kubernetes版本：v1.24.2<br>运行时：containerd<br>系统：centos 7.9<br>系统内核：3.10.0-1160</p>
</blockquote>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>这是安装的不是生产级别的集群，只是为了演示使用。</p>
<p>（1）在每个节点添加host信息</p>
<p> cat &gt;&gt; &#x2F;etc&#x2F;hosts &lt;&lt; EOF192.168.205.128 kk-master&lt;br&gt;192.168.205.130 kk-node01&lt;br&gt;EOF&lt;br&gt;</p>
<p>（2）关闭防火墙和SELinux</p>
<p> systemctl stop firewalld<br> systemctl disable firewalld<br> setenforce 0<br> cat &#x2F;etc&#x2F;selinux&#x2F;config<br> SELINUX&#x3D;disabled</p>
<p>（3）优化内核参数</p>
<p>cat &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf &lt;&lt; EOF<br>net.bridge.bridge-nf-call-ip6tables &#x3D; 1<br>net.bridge.bridge-nf-call-iptables &#x3D; 1<br>net.ipv4.ip_forward &#x3D; 1<br>vm.swappiness&#x3D;0<br>EOF</p>
<p>执行以下命令使其生效：</p>
<p>modprobe br_netfilter &amp;&amp; sysctl -p &#x2F;etc&#x2F;sysctl.d&#x2F;k8s.conf</p>
<p>（4）关闭swap空间</p>
<p> swapoff -a</p>
<p>注释&#x2F;etc&#x2F;fstab文件中swap挂载。</p>
<p> cat &#x2F;etc&#x2F;fstab </p>
<p>（5）安装ipvs软件包</p>
<p>cat &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules &lt;&lt;EOF<br>#!&#x2F;bin&#x2F;bash<br>modprobe – ip_vs<br>modprobe – ip_vs_rr<br>modprobe – ip_vs_wrr<br>modprobe – ip_vs_sh<br>modprobe – nf_conntrack_ipv4<br>EOF<br>chmod 755 &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules &amp;&amp; bash &#x2F;etc&#x2F;sysconfig&#x2F;modules&#x2F;ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4 &amp;&amp; yum install ipset ipvsadm -y</p>
<p>（6）同步服务器时间</p>
<p> yum install chrony -y systemctl enable chronyd systemctl start chronyd chronyc sources</p>
<p>（7）安装containerd</p>
<p>yum install -y yum-utils device-mapper-persistent-data lvm2<br>yum-config-manager –add-repo <a target="_blank" rel="noopener" href="https://download.docker.com/linux/centos/docker-ce.repo">https://download.docker.com/linux/centos/docker-ce.repo</a><br>yum list | grep containerd<br>yum install containerd -y</p>
<p>创建containerd配置文件。</p>
<p>mkdir -p &#x2F;etc&#x2F;containerd<br>containerd config default &gt; &#x2F;etc&#x2F;containerd&#x2F;config.toml<br>sed -i “s#k8s.gcr.io#registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers#g” &#x2F;etc&#x2F;containerd&#x2F;config.toml<br>sed -i ‘s#SystemdCgroup &#x3D; false#SystemdCgroup &#x3D; true#g’ &#x2F;etc&#x2F;containerd&#x2F;config.toml<br>sed -i “s#<a target="_blank" rel="noopener" href="https://registry-1.docker.io/#https://registry.cn-hangzhou.aliyuncs.com#g">https://registry-1.docker.io#https://registry.cn-hangzhou.aliyuncs.com#g</a>“ &#x2F;etc&#x2F;containerd&#x2F;config.toml</p>
<p>启动containerd。</p>
<p> systemctl daemon-reload systemctl enable containerd systemctl restart containerd</p>
<p>（8）安装Kubernetes组件</p>
<p>cat &lt;<EOF > &#x2F;etc&#x2F;yum.repos.d&#x2F;kubernetes.repo<br>[kubernetes]<br>name&#x3D;Kubernetes<br>baseurl&#x3D;<a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64">http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</a><br>enabled&#x3D;1<br>gpgcheck&#x3D;0<br>repo_gpgcheck&#x3D;0<br>gpgkey&#x3D;<a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg">http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</a> <a target="_blank" rel="noopener" href="http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg">http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</a><br>EOF</p>
<p>安装指定版本的组件。</p>
<p> yum install -y kubelet-1.24.2 kubeadm-1.24.2 kubectl-1.24.2</p>
<p>设置运行时。</p>
<p> crictl config runtime-endpoint &#x2F;run&#x2F;containerd&#x2F;containerd.sock</p>
<p>设置kubelet为自启动。</p>
<p> systemctl daemon-reload systemctl enable kubelet &amp;&amp; systemctl start kubelet</p>
<h2 id="初始化集群"><a href="#初始化集群" class="headerlink" title="初始化集群"></a>初始化集群</h2><p>上面把基础环境准备好了，现在开始真正的进行集群初始化。</p>
<h3 id="初始化master节点"><a href="#初始化master节点" class="headerlink" title="初始化master节点"></a>初始化master节点</h3><p>然后接下来在 master 节点配置 kubeadm 初始化文件，可以通过如下命令导出默认的初始化配置：</p>
<p>$ kubeadm config &lt;span style&#x3D;”color: #f92672;font-weight: bold;line-height: 26px;”&gt;print init-defaults &gt; kubeadm.yaml&lt;br&gt;</p>
<p>然后根据我们自己的需求修改配置，比如修改 imageRepository 的值，kube-proxy 的模式为 ipvs，需要注意的是由于我们使用的containerd作为运行时，所以在初始化节点的时候需要指定<code>cgroupDriver</code>为<code>systemd</code>【1】</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span></span><br><span class="line"><span class="attr">bootstrapTokens:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">groups:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">system:bootstrappers:kubeadm:default-node-token</span></span><br><span class="line">  <span class="attr">token:</span> <span class="string">abcdef.0123456789abcdef</span></span><br><span class="line">  <span class="attr">ttl:</span> <span class="string">24h0m0s</span></span><br><span class="line">  <span class="attr">usages:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">signing</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">authentication</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">InitConfiguration</span></span><br><span class="line"><span class="attr">localAPIEndpoint:</span></span><br><span class="line">  <span class="attr">advertiseAddress:</span> <span class="number">192.168</span><span class="number">.205</span><span class="number">.128</span></span><br><span class="line">  <span class="attr">bindPort:</span> <span class="number">6443</span></span><br><span class="line"><span class="attr">nodeRegistration:</span></span><br><span class="line">  <span class="attr">criSocket:</span> <span class="string">unix:///var/run/containerd/containerd.sock</span></span><br><span class="line">  <span class="attr">imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">taints:</span> <span class="literal">null</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiServer:</span></span><br><span class="line">  <span class="attr">timeoutForControlPlane:</span> <span class="string">4m0s</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeadm.k8s.io/v1beta3</span></span><br><span class="line"><span class="attr">certificatesDir:</span> <span class="string">/etc/kubernetes/pki</span></span><br><span class="line"><span class="attr">clusterName:</span> <span class="string">kubernetes</span></span><br><span class="line"><span class="attr">controllerManager:</span> &#123;&#125;</span><br><span class="line"><span class="attr">dns:</span> &#123;&#125;</span><br><span class="line"><span class="attr">etcd:</span></span><br><span class="line">  <span class="attr">local:</span></span><br><span class="line">    <span class="attr">dataDir:</span> <span class="string">/var/lib/etcd</span></span><br><span class="line"><span class="attr">imageRepository:</span> <span class="string">registry.cn-hangzhou.aliyuncs.com/google_containers</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">kubernetesVersion:</span> <span class="number">1.24</span><span class="number">.2</span></span><br><span class="line"><span class="attr">networking:</span></span><br><span class="line">  <span class="attr">dnsDomain:</span> <span class="string">cluster.local</span></span><br><span class="line">  <span class="attr">serviceSubnet:</span> <span class="number">10.96</span><span class="number">.0</span><span class="number">.0</span><span class="string">/12</span></span><br><span class="line"><span class="attr">scheduler:</span> &#123;&#125;</span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubeproxy.config.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeProxyConfiguration</span></span><br><span class="line"><span class="attr">mode:</span> <span class="string">ipvs</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubelet.config.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">KubeletConfiguration</span></span><br><span class="line"><span class="attr">cgroupDriver:</span> <span class="string">systemd</span></span><br></pre></td></tr></table></figure>

<p>然后使用上面的配置文件进行初始化：</p>
<p>The command to initialize the Kubernetes control-plane and join worker nodes is as follows:</p>
<ol>
<li><p>Initialize the Kubernetes control-plane:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --config=kubeadm.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>After the control-plane has initialized successfully, run the following commands as a regular user to start using the cluster:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
</li>
<li><p>Deploy a pod network to the cluster by running:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f [podnetwork].yaml</span><br></pre></td></tr></table></figure>
<p>Replace <code>[podnetwork].yaml</code> with the appropriate pod network configuration file.</p>
</li>
<li><p>To join worker nodes to the cluster, run the following command on each worker node as root:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 192.168.205.128:6443 --token abcdef.0123456789abcdef --discovery-token-ca-cert-hash sha256:51b5e566d3f95aaf3170916d67958bc16cb1b44934885a857b07ee58f041334a</span><br></pre></td></tr></table></figure>
<p>Replace <code>192.168.205.128:6443</code> with the appropriate control-plane endpoint and token information.</p>
</li>
</ol>
<p>如上输出表示master节点初始化成功。</p>
<h3 id="初始化node节点"><a href="#初始化node节点" class="headerlink" title="初始化node节点"></a>初始化node节点</h3><p>在初始化node节点的时候，必须把kubernetes需要的组件安装上。确保安装完成后，使用初始化master节点成功后输出的命令加入节点即可。</p>
<p> kubeadm join 192.168.205.128:6443 –token abcdef.0123456789abcdef \        –discovery-token-ca-cert-hash sha256:51b5e566d3f95aaf3170916d67958bc16cb1b44934885a857b07ee58f041334a&lt;br&gt;</p>
<p>然后可以在master节点使用kubectl get node查看节点是否加入。</p>
<p> kubectl get noNAME        STATUS     ROLES           AGE     VERSION&lt;br&gt;kk-node01   NotReady   &lt;none&gt;          15s     v1.24.2&lt;br&gt;master      NotReady   control-plane   3m29s   v1.24.2&lt;br&gt;</p>
<h3 id="初始化网络"><a href="#初始化网络" class="headerlink" title="初始化网络"></a>初始化网络</h3><p>通过上面<code>kubectl get node</code>查看节点信息的时候发现节点的<code>STATUS</code>是<code>NotReady</code>，这是因为现在整个集群还没有相应的网络插件，导致整个集群并不能正常的运行，下面我们就来安装对应的网络插件。</p>
<p>网络插件的选择有很多种，比如flannel，calico等。</p>
<p>（1）下载calico的yaml清单</p>
<p> wget <a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/projectcalico/calico/master/manifests/calico.yaml">https://raw.githubusercontent.com/projectcalico/calico/master/manifests/calico.yaml</a></span><br></p>
<p>（2）安装calico</p>
<p> kubectl apply -f calico.yaml</p>
<p>（3）在集群中查看安装结果</p>
<p> kubectl get po -n kube-system | grep calicocalico-kube-controllers-5d49fc6c56-szm6v   1&#x2F;1     Running   0          3m21s&lt;br&gt;calico-node-66q62                          1&#x2F;1     Running   0          3m21s&lt;br&gt;calico-node-lwrcm                          1&#x2F;1     Running   0          3m21s&lt;br&gt;</p>
<p>现在可以看到kubernetes所有节点的状态变成<code>Ready</code>了。</p>
<p> kubectl get noNAME        STATUS   ROLES           AGE   VERSION&lt;br&gt;kk-node01   Ready    &lt;none&gt;          26m   v1.24.2&lt;br&gt;master      Ready    control-plane   29m   v1.24.2&lt;br&gt;</p>
<h3 id="安装Dashboard"><a href="#安装Dashboard" class="headerlink" title="安装Dashboard"></a>安装Dashboard</h3><p>上面集群安装完成后，基本都需要使用命令行进行操作，如果为了提升集群的可视化，可以安装一些Dashboard。</p>
<p>目前市面上的Dashboard有很多，比如kubesphere、kuboard、kubernetes dashboard等。这里安装的是kubernetes dashboard，其他可视化产品可以自己去了解并使用。</p>
<p>（1）使用如下命令进行安装</p>
<p> kubectl apply -f <a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.0/aio/deploy/recommended.yaml">https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.0/aio/deploy/recommended.yaml</a></span><br></p>
<p>（2）查看安装情况</p>
<p> kubectl get po -n kubernetes-dashboard NAME                                         READY   STATUS    RESTARTS   AGE&lt;br&gt;dashboard-metrics-scraper-7bfdf779ff-f9zwn   1&#x2F;1     Running   0          41s&lt;br&gt;kubernetes-dashboard-6cdd697d84-lvzvz        1&#x2F;1     Running   0          41s&lt;br&gt;</p>
<p>（3）访问<br>首先将kubernetes-dashboard的service改成NodePort，然后通过节点IP+NodePort端口进行访问。</p>
<p>修改完成过后信息如下。</p>
<p> kubectl get svc -n kubernetes-dashboard NAME                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE&lt;br&gt;dashboard-metrics-scraper   ClusterIP   10.109.224.102   &lt;none&gt;        8000&#x2F;TCP        113s&lt;br&gt;kubernetes-dashboard        NodePort    10.101.69.180    &lt;none&gt;        443:30497&#x2F;TCP   113s&lt;br&gt;</p>
<p>在浏览器输入<code>https://192.168.205.128:30497</code>进行访问，如下：<img src="/images/1708507702-12d5366c17c951cdb2402fe56548bb1b.png" alt="图片"></p>
<p>这里访问要使用<code>token</code>或者<code>kubeconfig</code>，这里使用token进行访问。</p>
<p>（1）生成token，这里直接生成admin级别的token。</p>
<p>apiVersion: v1<br>kind: ClusterRoleBinding<br>metadata:<br>name: dashboard-admin<br>annotations:<br>rbac.authorization.kubernetes.io&#x2F;autoupdate: “true”<br>roleRef:<br>kind: ClusterRole<br>name: admin<br>apiGroup: rbac.authorization.k8s.io<br>subjects:</p>
<p>kind: ServiceAccount<br>name: dashboard-admin<br>namespace: kube-system<br>apiVersion: v1<br>kind: Secret<br>type: kubernetes.io&#x2F;service-account-token<br>metadata:<br>name: dashboard-admin<br>namespace: kube-system<br>annotations:<br>kubernetes.io&#x2F;service-account.name: “dashboard-admin”</p>
<p> 说明：从kubernetes 1.24版本开始，移除了创建serviceaccount自动创建secret token的功能，所以需要自己创建secret token和serviceaccount进行关联。</p>
<p>（2）获取token</p>
<p>kubectl -n kube-system get secret dashboard-admin -o jsonpath&#x3D;{.data.token} | base64 -d</p>
<p>然后就可以登录查看集群信息了。<img src="/images/1708507702-b31e7b28d69127f40593814b6d7311ff.png" alt="图片"></p>
<h1 id="更新集群"><a href="#更新集群" class="headerlink" title="更新集群"></a>更新集群</h1><p>集群的更新操作有很多，比如创建或删除应用、添加或者删除节点等，这里主要介绍几种常用的操作：</p>
<ul>
<li><p>升级集群</p>
</li>
<li><p>更新集群证书</p>
</li>
<li><p>添加或删除集群</p>
</li>
</ul>
<h3 id="升级集群"><a href="#升级集群" class="headerlink" title="升级集群"></a>升级集群</h3><p>Kubernetes社区新版本的推出速度很快的，至少保持一年3个版本的迭代。在实际生产中，我们可能不会频繁的升级集群，因为这样的动作太大，可能导致其他生产问题。</p>
<p>但是，有时候会因为某些原因（比如软件版本兼容性、集群BUG等）不得不做升级集群的操作，所以，有必要掌握集群的升级方法以备不时之需。</p>
<h4 id="升级前准备"><a href="#升级前准备" class="headerlink" title="升级前准备"></a>升级前准备</h4><ul>
<li><p>升级前，需要认真阅读每个版本的?CHANGELOG。</p>
</li>
<li><p>务必备份所有重要组件，例如存储在数据库中应用层面的状态。kubeadm upgrade 不会影响你的工作负载，只会涉及 Kubernetes 内部的组件，但备份终究是好的。</p>
</li>
<li><p>可以小版本升级，也可以跨一个大版本升级，不建议跨两个大版本升级</p>
</li>
</ul>
<h4 id="升级目标"><a href="#升级目标" class="headerlink" title="升级目标"></a>升级目标</h4><p>现在集群的版本是1.24.0，预计升级的目标版本是1.24.2。</p>
<p> kubectl get nodes NAME        STATUS   ROLES           AGE     VERSION&lt;br&gt;kk-master   Ready    control-plane   7m20s   v1.24.0&lt;br&gt;kk-node01   Ready    &lt;none&gt;          6m40s   v1.24.0&lt;br&gt;</p>
<h4 id="备份集群"><a href="#备份集群" class="headerlink" title="备份集群"></a>备份集群</h4><p>kubeadm upgrade 不会影响你的工作负载，只会涉及 Kubernetes 内部的组件，但备份终究是好的。这里主要是对集群的所有资源进行备份，我使用的是一个开源的脚本，项目地址是：?<a target="_blank" rel="noopener" href="https://github.com/solomonxu/k8s-backup-restore">https://github.com/solomonxu/k8s-backup-restore</a></p>
<p>（1）下载脚本</p>
<p> mkdir -p &#x2F;data cd &#x2F;data git clone <a target="_blank" rel="noopener" href="https://github.com/solomonxu/k8s-backup-restore.git">https://github.com/solomonxu/k8s-backup-restore.git</a></span><br></p>
<p>（2）执行备份</p>
<p> cd &#x2F;data&#x2F;k8s-backup-restore .&#x2F;bin&#x2F;k8s_backup.sh </p>
<p>如果要恢复怎么办？只需要执行如下步骤。（1）创建恢复目录</p>
<p> mkdir -p &#x2F;data&#x2F;k8s-backup-restore&#x2F;data&#x2F;restore</p>
<p>（2）将需要恢复的YAML清单复制到该目录下</p>
<p> cp devops_deployments_gitlab.yaml ..&#x2F;..&#x2F;restore&#x2F;</p>
<p>（3）执行恢复命令</p>
<p> cd &#x2F;data&#x2F;k8s-backup-restore .&#x2F;bin&#x2F;k8s_restore.sh</p>
<h4 id="升级控制节点"><a href="#升级控制节点" class="headerlink" title="升级控制节点"></a>升级控制节点</h4><p>（1）确定要升级的版本包是否存在</p>
<p> yum list –showduplicates kubeadm –disableexcludes&#x3D;kubernetes</p>
<p>（2）升级kubeadm到指定版本</p>
<p> yum install -y kubeadm-1.24.2-0 –disableexcludes&#x3D;kubernetes</p>
<p>执行以下命令查看是否升级成功。</p>
<p> kubeadm versionkubeadm version: &amp;version.Info{Major:”1”, Minor:”24”, GitVersion:”v1.24.2”, GitCommit:”f66044f4361b9f1f96f0053dd46cb7dce5e990a8”, GitTreeState:”clean”, BuildDate:”2022-06-15T14:20:54Z”, GoVersion:”go1.18.3”, Compiler:”gc”, Platform:”linux&#x2F;amd64”}&lt;br&gt;</p>
<p>（3）排空节点</p>
<p> kubectl cordon kk-master kubectl drain kk-master </p>
<p>（4）运行升级计划，查看是否可以升级</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get cm kubeadm-config -o yaml</span><br></pre></td></tr></table></figure>

<p>（5）升级集群</p>
<p> kubeadm upgrade apply v1.24.2 –config kubeadm.yaml </p>
<p>看到如下输出表示升级成功。</p>
<p>……&lt;br&gt;[upgrade&#x2F;successful] SUCCESS! Your cluster was upgraded to “v1.24.2”. Enjoy!&lt;br&gt;……&lt;br&gt;</p>
<p>（6）取消节点调度保护</p>
<p> kubectl uncordon kk-master</p>
<p>（7）由于这里Master即是控制平面，也是节点，所以需要对其在进行一次升级</p>
<p> kubeadm upgrade node</p>
<p>（8）升级kubectl和kubelet</p>
<p> yum install -y kubelet-1.24.2-0 kubectl-1.24.2-0 –disableexcludes&#x3D;kubernetes</p>
<p>（9）重启kubelet</p>
<p> systemctl daemon-reload systemctl restart kubelet</p>
<h4 id="升级节点"><a href="#升级节点" class="headerlink" title="升级节点"></a>升级节点</h4><p>（1）升级kubeadm</p>
<p> yum install -y kubeadm-1.24.2-0 –disableexcludes&#x3D;kubernetes</p>
<p>（2）设置节点不可调度且排空节点</p>
<p> kubectl cordon kk-node01 kubectl drain kk-node01</p>
<p>（3）升级节点</p>
<p> kubeadm upgrade node</p>
<p>（4）升级kubelet</p>
<p> yum install -y kubelet-1.24.2-0 –disableexcludes&#x3D;kubernetes</p>
<p>（5）重启节点</p>
<p> systemctl daemon-reload systemctl restart kubelet</p>
<p>（6）恢复节点可调度</p>
<p> kubectl uncordon kk-node01</p>
<h4 id="验证集群"><a href="#验证集群" class="headerlink" title="验证集群"></a>验证集群</h4><p>（1）查看集群状态信息是否正常</p>
<p> kubectl get noNAME        STATUS   ROLES           AGE   VERSION&lt;br&gt;kk-master   Ready    control-plane   33m   v1.24.2&lt;br&gt;kk-node01   Ready    &lt;none&gt;          32m   v1.24.2&lt;br&gt;</p>
<p>（2）查看集群Pod是否正常</p>
<p>NAMESPACE     NAME                                       READY   STATUS    RESTARTS   AGE<br>kube-system   calico-kube-controllers-5d49fc6c56-pq57d   1&#x2F;1     Running   0          31m<br>kube-system   calico-node-rjdqh                          1&#x2F;1     Running   0          31m<br>kube-system   calico-node-s8475                          1&#x2F;1     Running   0          31m<br>kube-system   coredns-7f74c56694-qpvmv                   1&#x2F;1     Running   0          35m<br>kube-system   coredns-7f74c56694-ww8kb                   1&#x2F;1     Running   0          35m<br>kube-system   etcd-kk-master                             1&#x2F;1     Running   0          35m<br>kube-system   kube-apiserver-kk-master                   1&#x2F;1     Running   0          11m<br>kube-system   kube-controller-manager-kk-master          1&#x2F;1     Running   0          10m<br>kube-system   kube-proxy-5pf65                           1&#x2F;1     Running   0          10m<br>kube-system   kube-proxy-mcxlq                           1&#x2F;1     Running   0          10m<br>kube-system   kube-scheduler-kk-master                   1&#x2F;1     Running   0          10m</p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>在升级过程中如果升级失败并且没有回滚，可以继续执行<code>kubeadm upgrade</code>。如果要从故障状态恢复，可以执行<code>kubeadm upgrade --force</code>。</p>
<p>在升级期间，会在<code>/etc/kubernetes/tmp</code>目录下生成备份文件：</p>
<ul>
<li><p>kubeadm-backup-etcd-</p>
</li>
<li><p>kubeadm-backup-manifests-</p>
</li>
</ul>
<p>kubeadm-backup-etcd中包含本地etcd的数据备份，如果升级失败并且无法修复，可以将其数据复制到etcd数据目录进行手动修复。</p>
<p>kubeadm-backup-manifests中保存的是节点静态pod的YAML清单，如果升级失败并且无法修复，可以将其复制到<code>/etc/kubernetes/manifests</code>下进行手动修复。</p>
<h3 id="升级证书"><a href="#升级证书" class="headerlink" title="升级证书"></a>升级证书</h3><p>升级集群可能不会经常发送，但是升级证书应该是一个常态化操作。</p>
<p>使用kubeadm安装的证书默认有效期是一年，也就是说在证书过期之前必须对证书进行升级，不然就会导致整个集群异常。</p>
<p>可以使用如下命令查看集群的证书情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED</span><br><span class="line">admin.conf                 Jul 04, 2023 08:43 UTC   364d            ca                      no      </span><br><span class="line">apiserver                  Jul 04, 2023 08:39 UTC   364d            ca                      no      </span><br><span class="line">apiserver-etcd-client      Jul 04, 2023 08:39 UTC   364d            etcd-ca                 no      </span><br><span class="line">apiserver-kubelet-client   Jul 04, 2023 08:39 UTC   364d            ca                      no      </span><br><span class="line">controller-manager.conf    Jul 04, 2023 08:40 UTC   364d            ca                      no      </span><br><span class="line">etcd-healthcheck-client    Jul 04, 2023 08:16 UTC   364d            etcd-ca                 no      </span><br><span class="line">etcd-peer                  Jul 04, 2023 08:16 UTC   364d            etcd-ca                 no      </span><br><span class="line">etcd-server                Jul 04, 2023 08:16 UTC   364d            etcd-ca                 no      </span><br><span class="line">front-proxy-client         Jul 04, 2023 08:39 UTC   364d            front-proxy-ca          no      </span><br><span class="line">scheduler.conf             Jul 04, 2023 08:40 UTC   364d            ca                      no      </span><br><span class="line"></span><br><span class="line">CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED</span><br><span class="line">ca                      Jul 01, 2032 08:16 UTC   9y              no      </span><br><span class="line">etcd-ca                 Jul 01, 2032 08:16 UTC   9y              no      </span><br><span class="line">front-proxy-ca          Jul 01, 2032 08:16 UTC   9y              no</span><br></pre></td></tr></table></figure>

<p>（1）使用<code>kubeadm certs check-expiration</code>检查证书是否过期</p>
<p>（2）备份证书</p>
<p> mkdir &#x2F;etc&#x2F;kubernetes.bak.20220704 cp -r &#x2F;etc&#x2F;kubernetes&#x2F;* &#x2F;etc&#x2F;kubernetes.bak.20220704</p>
<p>（3）备份etcd数据库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 备份数据目录</span></span><br><span class="line"><span class="built_in">cp</span> -r /var/lib/etcd /var/lib/etcd.bak</span><br><span class="line"></span><br><span class="line"><span class="comment"># 快照备份</span></span><br><span class="line"><span class="built_in">export</span> ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints localhost:2379 snapshot save snapshot.db \</span><br><span class="line">  --cacert=/etc/kubernetes/pki/etcd/ca.crt  \</span><br><span class="line">  --cert=/etc/kubernetes/pki/etcd/server.crt \</span><br><span class="line">  --key=/etc/kubernetes/pki/etcd/server.key</span><br><span class="line"></span><br><span class="line"><span class="comment"># 快照恢复命令</span></span><br><span class="line">etcdctl snapshot restore snapshot.db --name m3 --data-dir=/home/etcd_data</span><br></pre></td></tr></table></figure>

<p>（4）更新证书</p>
<p> kubeadm alpha certs renew all –config&#x3D;kubeadm.yaml</p>
<p>（5）更新kubeconfig</p>
<p> kubeadm init phase kubeconfig all –config kubeadm.yaml</p>
<p>（6）覆盖控制节点的kubeconfig</p>
<p> mv $HOME&#x2F;.kube&#x2F;config $HOME&#x2F;.kube&#x2F;config.old cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config&lt;span style&#x3D;”color: #75715e;line-height: 26px;”&gt;#&lt;span style&#x3D;”line-height: 26px;”&gt; chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config</p>
<p>（7）完成后重启kubernetes控制面的组件</p>
<p> cd &#x2F;etc&#x2F;kubernetes&#x2F;manifests mv *.yaml ..&#x2F; mv ..&#x2F;*.yaml .</p>
<blockquote>
<p>containerd运行时没有重启容器的命令，所以这里采用是直接移出再拷贝进来的操作。如果底层安装有docker，可以使用docker命令进行重启。</p>
</blockquote>
<p>（8）检查证书是否更新</p>
<p>$ echo | openssl s_client -showcerts -connect 127.0.0.1:6443 -servername api 2&gt;&#x2F;dev&#x2F;null | openssl x509 -noout -enddate  </p>
<p>$ kubeadm certs check-expiration<br>[check-expiration] Reading configuration from the cluster…<br>[check-expiration] FYI: You can look at this config file with ‘kubectl -n kube-system get cm kubeadm-config -o yaml’  </p>
<p>CERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED<br>admin.conf                 Jul 04, 2023 09:21 UTC   364d            ca                      no<br>apiserver                  Jul 04, 2023 09:21 UTC   364d            ca                      no<br>apiserver-etcd-client      Jul 04, 2023 09:21 UTC   364d            etcd-ca                 no<br>apiserver-kubelet-client   Jul 04, 2023 09:21 UTC   364d            ca                      no<br>controller-manager.conf    Jul 04, 2023 09:21 UTC   364d            ca                      no<br>etcd-healthcheck-client    Jul 04, 2023 09:21 UTC   364d            etcd-ca                 no<br>etcd-peer                  Jul 04, 2023 09:21 UTC   364d            etcd-ca                 no<br>etcd-server                Jul 04, 2023 09:21 UTC   364d            etcd-ca                 no<br>front-proxy-client         Jul 04, 2023 09:21 UTC   364d            front-proxy-ca          no<br>scheduler.conf             Jul 04, 2023 09:21 UTC   364d            ca                      no  </p>
<p>CERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED<br>ca                      Jul 01, 2032 08:16 UTC   9y              no<br>etcd-ca                 Jul 01, 2032 08:16 UTC   9y              no<br>front-proxy-ca          Jul 01, 2032 08:16 UTC   9y              no</p>
<p>（7）其他<br>默认情况下，kubeadm 使用 <code>/etc/kubernetes/kubelet.conf</code> 中指定的 <code>/var/lib/kubelet/pki/kubelet-client-current.pem</code> 符号链接 来配置 kubelet 自动轮换客户端证书。如果此轮换过程失败，你可能会在 kube-apiserver 日志中看到 诸如<code>x509: certificate has expired or is not yet valid</code>之类的错误。</p>
<p>要解决此问题，你必须执行以下步骤：</p>
<ol>
<li><p>从故障节点备份和删除 &#x2F;etc&#x2F;kubernetes&#x2F;kubelet.conf 和 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pki&#x2F;kubelet-client*。</p>
</li>
<li><p>在集群中具有 &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key 的、正常工作的控制平面节点上 执行 <code>kubeadm alpha kubeconfig user --org system:nodes --client-name system:node:$NODE &gt; kubelet.conf</code>。$NODE 必须设置为集群中现有故障节点的名称。手动修改生成的 kubelet.conf 以调整集群名称和服务器端点， 或传递 kubeconfig user –config（此命令接受 InitConfiguration）。如果你的集群没有 ca.key，你必须在外部对 kubelet.conf 中的嵌入式证书进行签名。</p>
</li>
<li><p>将得到的 kubelet.conf 文件复制到故障节点上，作为 &#x2F;etc&#x2F;kubernetes&#x2F;kubelet.conf。</p>
</li>
<li><p>在故障节点上重启 kubelet（systemctl restart kubelet），等待 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pki&#x2F;kubelet-client-current.pem 重新创建。</p>
</li>
<li><p>在故障节点上运行 kubeadm init phase kubelet-finalize all。这将使新的 kubelet.conf 文件使用 &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;pki&#x2F;kubelet-client-current.pem 并将重新启动 kubelet。</p>
</li>
<li><p>确保节点状况变为 Ready。</p>
</li>
</ol>
<blockquote>
<p>PS：除了使用上面方式升级集群证书之外，还可以通过升级集群版本的方式升级证书。</p>
</blockquote>
<h3 id="添加-删除节点"><a href="#添加-删除节点" class="headerlink" title="添加&#x2F;删除节点"></a>添加&#x2F;删除节点</h3><p>当集群节点不足以支撑业务的时候，我们也许会对集群进行扩容，也就是添加节点以满足日常需求。当集群节点比较空闲的时候，也会对集群进行缩容，也就是删除节点以节约开支。</p>
<p>所以添加&#x2F;删除节点在日常的工作中是比较常见的操作，而且整体操作也比较简单。</p>
<h4 id="添加节点"><a href="#添加节点" class="headerlink" title="添加节点"></a>添加节点</h4><p>添加节点的操作和初始化node节点一样，严格按照<code>环境准备</code>和<code>初始化Node节点</code>操作即可。</p>
<p>有几点需要注意：<br>（1）所有主机hosts添加新的主机</p>
<p>$ cat &gt;&gt; &#x2F;etc&#x2F;hosts &lt;&lt; EOF<br>192.168.205.128 kk-master<br>192.168.205.130 kk-node01<br>192.168.205.133 kk-node02<br>EOF</p>
<p>（2）查看集群token</p>
<p>$ kubeadm token list&lt;br&gt;</p>
<p>（3）如果token不存在就自己创建</p>
<p>$ kubeadm token create&lt;br&gt;</p>
<p>（4）获取ca证书sha256编码hash值</p>
<p>$ kubeadm join 192.168.205.128:6443 –token q0mjah.4k3oavynezdj8jf9 \<br>    –discovery-token-ca-cert-hash sha256:3d5c2e7d2532a4f085159d89de3ea2ea515e0784787b9c1adf0d3826c283733c \<br>    –node-name kk-node02</p>
<p>（5）然后可以看到集群添加成功</p>
<p>$ kubectl get no&lt;br&gt;NAME        STATUS   ROLES           AGE    VERSION&lt;br&gt;kk-master   Ready    control-plane   111m   v1.24.2&lt;br&gt;kk-node01   Ready    &lt;none&gt;          111m   v1.24.2&lt;br&gt;kk-node02   Ready    &lt;none&gt;          54s    v1.24.2&lt;br&gt;</p>
<h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><p>删除节点的操作也非常简单，总结如下：<br>（1）设置节点不可调度</p>
<p>$ kubectl cordon kk-node02&lt;br&gt;</p>
<p>（2）驱逐待删除节点上面的Pod</p>
<p>$  kubectl drain kk-node02 –ignore-daemonsets&#x3D;&lt;span style&#x3D;”color: #f92672;font-weight: bold;line-height: 26px;”&gt;true –delete-emptydir-data&#x3D;&lt;span style&#x3D;”color: #f92672;font-weight: bold;line-height: 26px;”&gt;true</p>
<p>（3）然后进行节点删除</p>
<p>$ kubectl delete nodes kk-node02&lt;br&gt;</p>
<p>现在，节点已经从整个集群移除。</p>
<h1 id="备份集群-1"><a href="#备份集群-1" class="headerlink" title="备份集群"></a>备份集群</h1><p>对任何系统来说，备份都必不可少，比如备份数据库，备份文件系统，备份配置文件等。</p>
<p>对于Kubernetes来说，备份也尤为重要。Kubernetes中的所有对象都是存储在Etcd中，我们可以直接对数据库进行备份。当然，Kubernetes中所有对象的配置文件也是可见的，我们也可以直接对这些配置文件进行备份。</p>
<p>在真正使用中，一般会做两手方案，即备份数据库和备份配置清单。如果其中一种方案无法进行恢复，还可以通过另一种来兜底。</p>
<p>这里同时会介绍备份Etcd数据库和备份集群配置清单，以方便各位在实际中酌情处理。</p>
<h2 id="备份数据库"><a href="#备份数据库" class="headerlink" title="备份数据库"></a>备份数据库</h2><h3 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h3><p>备份数据库比较简单，可以直接用etcdctl进行备份，在上面升级证书章节有简单提到。</p>
<p>（1）安装etcdctl命令，在?<a target="_blank" rel="noopener" href="https://github.com/etcd-io/etcd/releases%E4%B8%8A%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84etcd%E5%AE%89%E8%A3%85%E5%8C%85">https://github.com/etcd-io/etcd/releases上下载对应的etcd安装包</a></p>
<p>$ wget <a target="_blank" rel="noopener" href="https://github.com/etcd-io/etcd/releases/download/v3.5.3/etcd-v3.5.3-linux-amd64.tar.gz">https://github.com/etcd-io/etcd/releases/download/v3.5.3/etcd-v3.5.3-linux-amd64.tar.gz</a><br>$ tar xf etcd-v3.5.3-linux-amd64.tar.gz<br>$ mv etcd-v3.5.3-linux-amd64&#x2F;etcdctl &#x2F;usr&#x2F;<span style="color: #a6e22e;line-height: 26px;">local</span>&#x2F;bin&#x2F;<br></p>
<p>（2）检验命令</p>
<p>$ etcdctl version&lt;br&gt;etcdctl version: 3.5.3&lt;br&gt;API version: 3.5&lt;br&gt;</p>
<p>（3）进行备份操作</p>
<p>$ export ETCDCTL_API&#x3D;3&lt;br&gt;$ etcdctl –endpoints localhost:2379 snapshot save snapshot.db \&lt;br&gt;          –cacert&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt  \&lt;br&gt;          –cert&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.crt \&lt;br&gt;          –key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.key&lt;br&gt;</p>
<p>备份Ectd需要指定证书，如果执行节点没有，可以从主节点拷贝过来。</p>
<p>执行完成过后，可以在当前目录查看到备份结果。</p>
<p>$ export ETCDCTL_API&#x3D;3&lt;br&gt;$ etcdctl –endpoints localhost:2379 snapshot save snapshot.db \&lt;br&gt;&gt;           –cacert&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt  \&lt;br&gt;&gt;           –cert&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.crt \&lt;br&gt;&gt;           –key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.key&lt;br&gt;{“level”:”info”,”ts”:”2022-07-04T20:00:17.509+0800”,”caller”:”snapshot&#x2F;v3_snapshot.go:65”,”msg”:”created temporary db file”,”path”:”snapshot.db.part”}&lt;br&gt;{“level”:”info”,”ts”:”2022-07-04T20:00:17.520+0800”,”logger”:”client”,”caller”:”v3&#x2F;maintenance.go:211”,”msg”:”opened snapshot stream; downloading”}&lt;br&gt;{“level”:”info”,”ts”:”2022-07-04T20:00:17.520+0800”,”caller”:”snapshot&#x2F;v3_snapshot.go:73”,”msg”:”fetching snapshot”,”endpoint”:”localhost:2379”}&lt;br&gt;{“level”:”info”,”ts”:”2022-07-04T20:00:17.544+0800”,”logger”:”client”,”caller”:”v3&#x2F;maintenance.go:219”,”msg”:”completed snapshot read; closing”}&lt;br&gt;{“level”:”info”,”ts”:”2022-07-04T20:00:17.556+0800”,”caller”:”snapshot&#x2F;v3_snapshot.go:88”,”msg”:”fetched snapshot”,”endpoint”:”localhost:2379”,”size”:”3.6 MB”,”took”:”now”}&lt;br&gt;{“level”:”info”,”ts”:”2022-07-04T20:00:17.556+0800”,”caller”:”snapshot&#x2F;v3_snapshot.go:97”,”msg”:”saved”,”path”:”snapshot.db”}&lt;br&gt;Snapshot saved at snapshot.db&lt;br&gt;$ ll&lt;br&gt;total 3472&lt;br&gt;-rw——-. 1 root root 3551264 Jul  4 20:00 snapshot.db&lt;br&gt;</p>
<p>但是，我们不可能每次都手动来进行备份，所以最好是通过定时任务来执行。为了更好的备份，这里编写了一个简单的shell脚本，然后再加到定时任务中。</p>
<p>&lt;span style&#x3D;”color: #75715e;line-height: 26px;”&gt;#&lt;span style&#x3D;”line-height: 26px;”&gt;! &#x2F;bin&#x2F;bash&lt;br&gt;&lt;br&gt;ETCDCTL_PATH&#x3D;’&#x2F;usr&#x2F;local&#x2F;bin&#x2F;etcdctl’&lt;br&gt;ENDPOINTS&#x3D;’192.168.205.128:2379’&lt;br&gt;ETCD_DATA_DIR&#x3D;”&#x2F;var&#x2F;lib&#x2F;etcd”&lt;br&gt;BACKUP_DIR&#x3D;”&#x2F;var&#x2F;backups&#x2F;kube_etcd&#x2F;etcd-$(date +%Y-%m-%d_%H:%M:%S)”&lt;br&gt;&lt;br&gt;ETCDCTL_CERT&#x3D;”&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.crt”&lt;br&gt;ETCDCTL_KEY&#x3D;”&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.key”&lt;br&gt;ETCDCTL_CA_FILE&#x3D;”&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt”&lt;br&gt;&lt;br&gt;&lt;br&gt;[ ! -d $BACKUP_DIR ] &amp;&amp; mkdir -p $BACKUP_DIR&lt;br&gt;&lt;br&gt;&lt;br&gt;export ETCDCTL_API&#x3D;2;$ETCDCTL_PATH backup –data-dir $ETCD_DATA_DIR –backup-dir $BACKUP_DIR&lt;br&gt;&lt;br&gt;sleep 3&lt;br&gt;&lt;br&gt;{&lt;br&gt;export ETCDCTL_API&#x3D;3;$ETCDCTL_PATH –endpoints&#x3D;”$ENDPOINTS” snapshot save $BACKUP_DIR&#x2F;snapshot.db \&lt;br&gt;                                   –cacert&#x3D;”$ETCDCTL_CA_FILE” \&lt;br&gt;                                   –cert&#x3D;”$ETCDCTL_CERT” \&lt;br&gt;                                   –key&#x3D;”$ETCDCTL_KEY”&lt;br&gt;} &gt; &#x2F;dev&#x2F;null &lt;br&gt;&lt;br&gt;sleep 3&lt;br&gt;&lt;br&gt;cd $BACKUP_DIR&#x2F;..&#x2F;;ls -lt |awk ‘{if(NR&gt;(5+1)){print “rm -rf “$9}}’|sh&lt;br&gt;</p>
<p>然后加入Linux定时任务，如下：</p>
<p>$ crontab -l&lt;br&gt;*&#x2F;30 * * * * &#x2F;opt&#x2F;etcd_back&#x2F;etcd_backup.sh&lt;br&gt;</p>
<h3 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h3><p>（1）停止kube-apiserver和etcd<br>我这里直接将所有静态Pod的YAML文件移除。</p>
<p>cd &#x2F;etc&#x2F;kubernetes&#x2F;manifests&lt;br&gt;mv *.yaml ..&#x2F;&lt;br&gt;</p>
<p>（2）移除etcd数据目录</p>
<p>$ mv &#x2F;var&#x2F;lib&#x2F;etcd{,.bak.20220705}&lt;br&gt;</p>
<p>（3）执行恢复</p>
<p>￥ ETCDCTL_API&#x3D;3 etcdctl snapshot restore snapshot.db   –name kk-master   –initial-cluster “kk-master&#x3D;<a target="_blank" rel="noopener" href="https://192.168.205.128:2380/">https://192.168.205.128:2380</a>“    –initial-cluster-token etcd-cluster   –initial-advertise-peer-urls <a target="_blank" rel="noopener" href="https://192.168.205.128:2380/">https://192.168.205.128:2380</a>   –data-dir&#x3D;&#x2F;var&#x2F;lib&#x2F;etcd<br></p>
<p>（4）重启Kubernetes组件</p>
<p> mv ..&#x2F;*.yaml .&lt;br&gt;</p>
<p>（5）验证集群状态</p>
<p>$ kubectl get nodes &lt;br&gt;NAME        STATUS   ROLES           AGE     VERSION&lt;br&gt;kk-master   Ready    control-plane   7h48m   v1.24.2&lt;br&gt;kk-node01   Ready    &lt;none&gt;          7h48m   v1.24.2&lt;br&gt;$ kubectl get po -A&lt;br&gt;NAMESPACE     NAME                                       READY   STATUS    RESTARTS            AGE&lt;br&gt;default       nginx1-585f98d7bf-45fnk                    1&#x2F;1     Running   0                   3h58m&lt;br&gt;kube-system   calico-kube-controllers-5d49fc6c56-pq57d   1&#x2F;1     Running   3 (&lt;invalid&gt; ago)   7h45m&lt;br&gt;kube-system   calico-node-rjdqh                          1&#x2F;1     Running   0                   7h45m&lt;br&gt;kube-system   calico-node-s8475                          1&#x2F;1     Running   0                   7h45m&lt;br&gt;kube-system   coredns-7f74c56694-qpvmv                   1&#x2F;1     Running   0                   7h48m&lt;br&gt;kube-system   coredns-7f74c56694-ww8kb                   1&#x2F;1     Running   0                   7h48m&lt;br&gt;kube-system   etcd-kk-master                             1&#x2F;1     Running   0                   7h48m&lt;br&gt;kube-system   kube-apiserver-kk-master                   1&#x2F;1     Running   2 (2m1s ago)        7h24m&lt;br&gt;kube-system   kube-controller-manager-kk-master          1&#x2F;1     Running   0                   7h24m&lt;br&gt;kube-system   kube-proxy-5pf65                           1&#x2F;1     Running   0                   7h24m&lt;br&gt;kube-system   kube-proxy-mcxlq                           1&#x2F;1     Running   0                   7h23m&lt;br&gt;kube-system   kube-scheduler-kk-master                   1&#x2F;1     Running   0                   7h24m&lt;br&gt;</p>
<h2 id="备份集群清单"><a href="#备份集群清单" class="headerlink" title="备份集群清单"></a>备份集群清单</h2><p>在Kubernetes的实际使用中，需要备份的集群清单主要有以下几种：</p>
<ul>
<li><p>Deployment类</p>
</li>
<li><p>StatfulSet类</p>
</li>
<li><p>DaemonSet类</p>
</li>
<li><p>Service类</p>
</li>
<li><p>ConfigMap类</p>
</li>
<li><p>Secret类</p>
</li>
<li><p>CronJob类</p>
</li>
<li><p>……</p>
</li>
</ul>
<p>备份整个清单可以用于快速恢复集群。而且由于备份etcd是备份的某一时刻的完整数据，无法选择备份哪些内容，并且其备份的数据除了etcd本身，其他程序不可读。</p>
<p>备份集群的方式有很多 ，简单点的可以按照“备份集群”的步骤使用脚本进行备份，由于上面已经介绍了这种方法，这章节将采用另外的工具——velero进行备份。</p>
<p>velero 是开源方案，项目地址：<a target="_blank" rel="noopener" href="https://velero.io/">https://velero.io/</a></p>
<p>velero的作用：</p>
<ul>
<li><p>灾备能力：提供备份恢复k8s集群的能力</p>
</li>
<li><p>迁移能力：提供拷贝集群资源到其他集群的能力</p>
</li>
</ul>
<p>和 etcd 备份的区别：</p>
<ul>
<li><p>etcd 的备份必须拥有 etcd 运维权限，有些用户无法操作 etcd，如多租户场景。</p>
</li>
<li><p>etcd 更适合单集群内数据备份，不太适合集群迁移</p>
</li>
<li><p>etcd 是当前状态备份，velero 可以做到只备份集群内的一部分资源</p>
</li>
</ul>
<p>velero 会在你的 k8s 集群上运行一个 server pod，然后配合 velero 客户端进行操作，安装过程可以参考文档，操作是很简单的。</p>
<h4 id="安装客户端"><a href="#安装客户端" class="headerlink" title="安装客户端"></a>安装客户端</h4><p>到<a target="_blank" rel="noopener" href="https://github.com/vmware-tanzu/velero/releases%E4%B8%8B%E8%BD%BD%E5%AF%B9%E5%BA%94%E7%9A%84%E7%89%88%E6%9C%AC%E5%B9%B6%E5%AE%89%E8%A3%85">https://github.com/vmware-tanzu/velero/releases下载对应的版本并安装</a></p>
<p>$ wget <a target="_blank" rel="noopener" href="https://github.com/vmware-tanzu/velero/releases/download/v1.9.0/velero-v1.9.0-linux-amd64.tar.gz">https://github.com/vmware-tanzu/velero/releases/download/v1.9.0/velero-v1.9.0-linux-amd64.tar.gz</a><br>$ tar xf velero-v1.9.0-linux-amd64.tar.gz<br>$ mv velero-v1.9.0-linux-amd64&#x2F;velero &#x2F;usr&#x2F;<span style="color: #a6e22e;line-height: 26px;">local</span>&#x2F;bin&#x2F;<br>$ velero version<br>Client:<br>        Version: v1.9.0<br>        Git commit: 6021f148c4d7721285e815a3e1af761262bff029<br>&lt;error getting server version: namespaces <span style="color: #a6e22e;line-height: 26px;">“velero”</span> not found&gt;<br></p>
<h4 id="安装服务端"><a href="#安装服务端" class="headerlink" title="安装服务端"></a>安装服务端</h4><p>安装服务端的方式有两种：</p>
<ul>
<li><p>使用velero客户端安装</p>
</li>
<li><p>使用helm chart安装</p>
</li>
</ul>
<p>这里使用velero客户端进行安装。velero的后端可以选择很多对象存储，比如阿里云OSS，mino等。由于阿里云OSS需要单独购买，所以这里采用minio作为后端存储。</p>
<h5 id="安装minio"><a href="#安装minio" class="headerlink" title="安装minio"></a>安装minio</h5><p>（1）添加helm源</p>
<p>$ helm repo add minio <a target="_blank" rel="noopener" href="https://helm.min.io/">https://helm.min.io/</a><br></p>
<p>（2）部署minio。由于这里只是做测试，所以没有做数据持久化等处理。</p>
<p>$ helm install minio \&lt;br&gt;  –namespace velero –create-namespace \&lt;br&gt;  –set accessKey&#x3D;minio,secretKey&#x3D;minio123 \&lt;br&gt;  –set mode&#x3D;standalone \&lt;br&gt;  –set service.type=NodePort \&lt;br&gt;  –set persistence.enabled=&lt;span style&#x3D;”color: #f92672;font-weight: bold;line-height: 26px;”&gt;false \&lt;br&gt;  minio&#x2F;minio&lt;br&gt;</p>
<p>（2）使用UI访问查看</p>
<p>$ kubectl get svc -n velero &lt;br&gt;NAME    TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE&lt;br&gt;minio   NodePort   10.110.75.97   &lt;none&gt;        9000:32000&#x2F;TCP   92s&lt;br&gt;</p>
<p><img src="/images/1708507702-eae3190165c690972320bb9cf089cce7.png" alt="图片"></p>
<p>image.png</p>
<p>登录用户名密码为：minio:minio123</p>
<h5 id="安装velero服务端"><a href="#安装velero服务端" class="headerlink" title="安装velero服务端"></a>安装velero服务端</h5><p>（1）在minio上创建buckrt<img src="/images/1708507702-b4c0d968523ce47ec7f72a1911efadf2.png" alt="图片">（2）在velero安装目录中创建credentials-velero，写入以下内容</p>
<p>[default]&lt;br&gt;aws_access_key_id&#x3D;minio&lt;br&gt;aws_secret_access_key&#x3D;minio123&lt;br&gt;</p>
<p>（3）安装velero</p>
<p>$ velero install    \&lt;br&gt;     –provider aws   \&lt;br&gt;     –bucket velero   \&lt;br&gt;     –image velero&#x2F;velero:v1.6.3  \&lt;br&gt;  –plugins velero&#x2F;velero-plugin-for-aws:v1.2.1  \&lt;br&gt;  –namespace velero  \&lt;br&gt;  –secret-file .&#x2F;credentials-velero  \&lt;br&gt;  –use-volume-snapshots&#x3D;&lt;span style&#x3D;”color: #f92672;font-weight: bold;line-height: 26px;”&gt;false \&lt;br&gt;     –use-restic \&lt;br&gt;  –backup-location-config region&#x3D;minio,s3ForcePathStyle&#x3D;”true”,s3Url&#x3D;<a target="_blank" rel="noopener" href="http://minio.velero.svc:9000/">http://minio.velero.svc:9000</a><br></p>
<p>（4）检查所有组件是否正常启动</p>
<p>$ kubectl get po -n velero&lt;br&gt;NAME                     READY   STATUS    RESTARTS   AGE&lt;br&gt;minio-6c9f559d5b-cpc2d   1&#x2F;1     Running   0          3m3s&lt;br&gt;restic-pq5bm             1&#x2F;1     Running   0          3m28s&lt;br&gt;velero-887577984-2tmm4   1&#x2F;1     Running   0          3m28s&lt;br&gt;</p>
<h3 id="执行备份操作"><a href="#执行备份操作" class="headerlink" title="执行备份操作"></a>执行备份操作</h3><p>（1）在default的namespace下创建一个nginx Pod</p>
<p>$ kubectl create deployment nginx –image nginx&lt;br&gt;</p>
<p>（2）执行备份操作，备份default下面的资源</p>
<p>$ velero backup create default-backup-20220705 –include-namespaces default –default-volumes-to-restic&lt;br&gt;</p>
<p>（3）在minio上可以查看到备份的目录已经存在<img src="/images/1708507702-951b58f806af7b79ddf2874c969989e6.png" alt="图片"></p>
<p>（4）现在删除default命名空间下的nginx Pod</p>
<p>$ kubectl delete deployment nginx&lt;br&gt;</p>
<p>（5）执行恢复操作</p>
<p>$ velero restore create –from-backup default-backup-20220705&lt;br&gt;</p>
<p>（6）可以看到default命名空间下的nginx Pod已经恢复</p>
<p>$ kubectl get po&lt;br&gt;NAME                    READY   STATUS    RESTARTS   AGE&lt;br&gt;nginx-8f458dc5b-z6fnh   1&#x2F;1     Running   0          38s&lt;br&gt;</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Kubernetes是应用的底座，如果底座出问题了，就谈不上应用的稳定性。在实际的工作中，对基础平台的备份尤为重要，可以在遇到不可描述的事情时有兜底的方案，所以，建议对Kubernetes做好备份操作，最好是定时备份。</p>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>上面就是常用的集群相关操作，熟练的掌握它们，并应用于实际，可以为你节约不少的时间成本。</p>
<p>当然除了这些常规操作，还有迁移集群、导入集群等，我认为其本质上还是备份还原的问题，只是会多考虑一点数据完整性和业务连续性，这跟具体的企业情况相关，所以在这里也不在赘述，如有兴趣可以私下交流。</p>
<h1 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h1><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG">https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG</a></li>
</ul>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=http://example.com/2024/02/21/Kubernetes%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Kubernetes/" rel="tag">Kubernetes</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2024/02/23/%E9%94%99%E8%AF%AF%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7%E5%B9%B3%E5%8F%B0-Sentry/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            错误日志监控平台-Sentry
          
        </div>
      </a>
    
    
      <a href="/2024/02/21/Kubernetes%E6%97%A5%E5%B8%B8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Kubernetes日常操作命令</div>
      </a>
    
  </nav>

  
   
  
   
    <script src="https://cdn.staticfile.org/twikoo/1.4.18/twikoo.all.min.js"></script>
    <div id="twikoo" class="twikoo"></div>
    <script>
        twikoo.init({
            envId: ""
        })
    </script>
 
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2015-2025
        <i class="ri-heart-fill heart_icon"></i> JinTao Li
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
        <li>
          <a href="https://beian.miit.gov.cn/" target="_black" rel="nofollow">鲁ICP备88888888</a>
        </li>
        
    </ul>
    <ul>
      
      <li>
          <img src="/images/beian.png"></img>
          <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=01234567890123" target="_black" rel="nofollow">青岛公安网备01234567890123号</a>
      </li>
        
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Lijintao&#39;s Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="https://blog.csdn.net/u013235026">CSDN</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" target="_blank" rel="noopener" href="https://www.cnblogs.com/jintaoli">博客园</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/images/272a163694dd8a415a43dbf85ac34778.jpg">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.staticfile.org/animejs/3.2.1/anime.min.js"></script>

<script src="/js/clickBoom1.js"></script>
 
<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->
 
<script src="/js/dz.js"></script>
 
<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=2142256392&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    
<script>
  const password = "jintao1210";
  const lock_password = window.sessionStorage.getItem("lock_password");
  console.log(password, lock_password);
  if (lock_password !== password) {
    Swal.fire({
      title: "请输入访问密码",
      input: "text",
      inputAttributes: {
        autocapitalize: "off",
      },
      showCancelButton: false,
      showLoaderOnConfirm: true,
      allowOutsideClick: false,
      confirmButtonText: "确定",
    }).then((result) => {
      console.log(result);
      if (result.isConfirmed) {
        console.log(password);
        if (result.value === password) {
          window.sessionStorage.setItem("lock_password", result.value);
        } else {
          Swal.fire({
            icon: "error",
            title: "密码错误，请重试",
            confirmButtonText: "确定",
            allowOutsideClick: false,
          }).then(() => {
            window.location.reload();
          });
        }
      }
    });
  }
</script>


  </div>
</body>

</html>